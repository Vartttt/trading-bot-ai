import os
import json
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from joblib import dump

from ai.transformer_trainer import ensure_artifacts, TRAIN_DATA_PATH, SCALER_PATH, MODEL_DIR
    ensure_artifacts,
    MODEL_DIR,
    TRAIN_DATA_PATH,
    SCALER_PATH,
    FEATURE_COLS_PATH,
    DEFAULT_FEATURE_COLS,
)

# –≥–∞—Ä–∞–Ω—Ç—É—î–º–æ, —â–æ —î –±–∞–∑–æ–≤—ñ —Ñ–∞–π–ª–∏
ensure_artifacts()

# —á–∏—Ç–∞—î–º–æ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ (—Å–ø–∏—Å–æ–∫ dict'—ñ–≤ –∑ —Ñ—ñ—á–∞–º–∏)
with open(TRAIN_DATA_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

df = pd.DataFrame(data)

# –≤–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–∞–±—ñ—Ä –∫–æ–ª–æ–Ω–æ–∫
if os.path.exists(FEATURE_COLS_PATH):
    with open(FEATURE_COLS_PATH, "r", encoding="utf-8") as f:
        feature_cols = json.load(f) or DEFAULT_FEATURE_COLS
else:
    feature_cols = [c for c in DEFAULT_FEATURE_COLS if c in df.columns]
    if not feature_cols:
        raise RuntimeError("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–¥–∞—Ç–Ω–∏—Ö —Ñ—ñ—á —É train_data.json")

X = df[feature_cols].fillna(0).values

# —Ç—Ä–µ–Ω—É—î–º–æ —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ scaler
scaler = StandardScaler()
scaler.fit(X)

os.makedirs(MODEL_DIR, exist_ok=True)
dump(scaler, SCALER_PATH)

print(f"‚úÖ Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {SCALER_PATH}")
print(f"üì¶ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ —Ñ—ñ—á—ñ: {feature_cols}")
